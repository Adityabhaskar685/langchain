{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DeciLM-6B Starter\n- 15x faster than llama in inference\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# setting up\n!pip install huggingface_hub --q\n!pip install transformers --q\n!pip install accelerate --q\n!pip install bitsandbytes>=0.30.0 --q","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:06:58.158751Z","iopub.execute_input":"2023-09-13T23:06:58.159153Z","iopub.status.idle":"2023-09-13T23:07:48.911995Z","shell.execute_reply.started":"2023-09-13T23:06:58.159122Z","shell.execute_reply":"2023-09-13T23:07:48.910721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# libararies\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:08:56.566661Z","iopub.execute_input":"2023-09-13T23:08:56.567061Z","iopub.status.idle":"2023-09-13T23:08:56.575179Z","shell.execute_reply.started":"2023-09-13T23:08:56.567010Z","shell.execute_reply":"2023-09-13T23:08:56.574205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the model","metadata":{}},{"cell_type":"code","source":"model_id = \"Deci/DeciLM-6b\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map = 'auto',\n    trust_remote_code= True\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:10:11.952791Z","iopub.execute_input":"2023-09-13T23:10:11.953188Z","iopub.status.idle":"2023-09-13T23:12:54.152873Z","shell.execute_reply.started":"2023-09-13T23:10:11.953155Z","shell.execute_reply":"2023-09-13T23:12:54.151828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess with a Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_id)\n\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel_inputs = tokenizer(\"A list of colors: red, blue\", return_tensors = 'pt').to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:15:39.258475Z","iopub.execute_input":"2023-09-13T23:15:39.258859Z","iopub.status.idle":"2023-09-13T23:15:39.408833Z","shell.execute_reply.started":"2023-09-13T23:15:39.258827Z","shell.execute_reply":"2023-09-13T23:15:39.407989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Text","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:15:45.562687Z","iopub.execute_input":"2023-09-13T23:15:45.563073Z","iopub.status.idle":"2023-09-13T23:15:45.592954Z","shell.execute_reply.started":"2023-09-13T23:15:45.563021Z","shell.execute_reply":"2023-09-13T23:15:45.591893Z"}}},{"cell_type":"code","source":"generated_ids = model.generate(**model_inputs,\n                               max_new_tokens = 40,\n                              num_beams = 5,\n                              early_stopping = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:21:38.082417Z","iopub.execute_input":"2023-09-13T23:21:38.082813Z","iopub.status.idle":"2023-09-13T23:21:42.821638Z","shell.execute_reply.started":"2023-09-13T23:21:38.082782Z","shell.execute_reply":"2023-09-13T23:21:42.820659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## decode\n- decoding the output tensors","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:19:48.408466Z","iopub.execute_input":"2023-09-13T23:19:48.408853Z","iopub.status.idle":"2023-09-13T23:19:48.418986Z","shell.execute_reply.started":"2023-09-13T23:19:48.408819Z","shell.execute_reply":"2023-09-13T23:19:48.418047Z"}}},{"cell_type":"code","source":"print(tokenizer.batch_decode(generated_ids, skip_special_tokens = True)[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:21:45.707028Z","iopub.execute_input":"2023-09-13T23:21:45.707545Z","iopub.status.idle":"2023-09-13T23:21:45.719427Z","shell.execute_reply.started":"2023-09-13T23:21:45.707502Z","shell.execute_reply":"2023-09-13T23:21:45.717231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How to Control Text Generation\n\nText generation with Hugging Face Transformers is both an art and a science.\n\nWhile model architecture and training data lay the foundation, parameters like num_beams, no_repeat_ngram_size, and early_stopping serve as fine-tuning knobs.\n\nBy understanding and adeptly adjusting these parameters, you can significantly enhance the quality of your model's generated text.\n\nExperiment, iterate, and find the perfect balance for your unique application!\n\nhow these three in particular influence the quality and characteristics of generated text:\n\n1) num_beams\n\n2) no_repeat_ngram_size\n\n3) early_stopping","metadata":{}},{"cell_type":"code","source":"def generate_text(prompt : str, max_new_token: int , temperature : float) -> str:\n    model_inputs = tokenizer(prompt, return_tensors = 'pt').to('cuda')\n    generated_ids = model.generate(**model_inputs, \n                                 max_new_tokens = max_new_token,\n                                 num_beams = 5,\n                                 no_repeat_ngram_size = 4,\n                                 early_stopping = True)\n    \n    decode_generation = tokenizer.batch_decode(generated_ids, skip_special_tokens = False)[0]\n    return print(decode_generation)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:34:18.096697Z","iopub.execute_input":"2023-09-13T23:34:18.097120Z","iopub.status.idle":"2023-09-13T23:34:18.105103Z","shell.execute_reply.started":"2023-09-13T23:34:18.097079Z","shell.execute_reply":"2023-09-13T23:34:18.104107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"In this blog post, we're going to talk about why waking up is\"\"\"\ngenerate_text(prompt, 500, 0.25)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:34:20.735238Z","iopub.execute_input":"2023-09-13T23:34:20.735607Z","iopub.status.idle":"2023-09-13T23:35:23.098804Z","shell.execute_reply.started":"2023-09-13T23:34:20.735576Z","shell.execute_reply":"2023-09-13T23:35:23.097746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = 'organic chemistry is'\ngenerate_text(prompt, 1000,0.25)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:44:57.887449Z","iopub.execute_input":"2023-09-13T23:44:57.887820Z","iopub.status.idle":"2023-09-13T23:47:15.115804Z","shell.execute_reply.started":"2023-09-13T23:44:57.887787Z","shell.execute_reply":"2023-09-13T23:47:15.114692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"Dear recruiter, I write this letter of recommendation for my toddler\nson for his application to the Hogwarts School of Monster Trucks and Classic Cars.\nHe has over 100 monster trucks and this is beyond an obsession\n\"\"\"\ngenerate_text(prompt, 500, 0.7)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:40:53.863254Z","iopub.execute_input":"2023-09-13T23:40:53.863665Z","iopub.status.idle":"2023-09-13T23:41:57.804205Z","shell.execute_reply.started":"2023-09-13T23:40:53.863630Z","shell.execute_reply":"2023-09-13T23:41:57.803073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"It was a clear dark night, a clear white moon. Warren G was on the street trying to consume\"\"\"\ngenerate_text(prompt, 500, 0.7)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T23:41:57.806456Z","iopub.execute_input":"2023-09-13T23:41:57.806900Z","iopub.status.idle":"2023-09-13T23:43:00.100616Z","shell.execute_reply.started":"2023-09-13T23:41:57.806859Z","shell.execute_reply":"2023-09-13T23:43:00.099513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}